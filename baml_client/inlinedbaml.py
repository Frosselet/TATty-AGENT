# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "agent-tools.baml": "// Agent Tool Definitions\n// Each tool has an action field with the tool name and its full description\n\nclass AgentTool {\n  action \"Agent\" @description(#\"\n    Launch a new agent that has access to the following tools: Bash, Glob, Grep, LS, exit_plan_mode, Read, WebFetch, TodoRead, TodoWrite. When you are searching for a keyword or file and are not confident that you will find the right match in the first few tries, use the Agent tool to perform the search for you.\n\n    When to use the Agent tool:\n    - If you are searching for a keyword like \"config\" or \"logger\", or for questions like \"which file does X?\", the Agent tool is strongly recommended\n\n    When NOT to use the Agent tool:\n    - If you want to read a specific file path, use the Read or Glob tool instead of the Agent tool, to find the match more quickly\n    - If you are searching for a specific class definition like \"class Foo\", use the Glob tool instead, to find the match more quickly\n    - If you are searching for code within a specific file or set of 2-3 files, use the Read tool instead of the Agent tool, to find the match more quickly\n    - Writing code and running bash commands (use other tools for that)\n\n    Usage notes:\n    1. Launch multiple agents concurrently whenever possible, to maximize performance; to do that, use a single message with multiple tool uses\n    2. When the agent is done, it will return a single message back to you. The result returned by the agent is not visible to the user. To show the user the result, you should send a text message back to the user with a concise summary of the result.\n    3. Each agent invocation is stateless. You will not be able to send additional messages to the agent, nor will the agent be able to communicate with you outside of its final report. Therefore, your prompt should contain a highly detailed task description for the agent to perform autonomously and you should specify exactly what information the agent should return back to you in its final and only message to you.\n    4. The agent's outputs should generally be trusted\n    5. Clearly tell the agent whether you expect it to write code or just to do research (search, file reads, web fetches, etc.), since it is not aware of the user's intent\n  \"#)\n  description string @description(\"A short (3-5 word) description of the task\")\n  prompt string @description(\"The task for the agent to perform\")\n}\n\nclass BashTool {\n  action \"Bash\" @description(#\"\n    Executes a given bash command in a persistent shell session with optional timeout, ensuring proper handling and security measures.\n\n    Before executing the command, please follow these steps:\n\n    1. Directory Verification:\n       - If the command will create new directories or files, first use the LS tool to verify the parent directory exists and is the correct location\n       - For example, before running \"mkdir foo/bar\", first use LS to check that \"foo\" exists and is the intended parent directory\n\n    2. Command Execution:\n       - Always quote file paths that contain spaces with double quotes (e.g., cd \"path with spaces/file.txt\")\n       - Examples of proper quoting:\n         - cd \"/Users/name/My Documents\" (correct)\n         - cd /Users/name/My Documents (incorrect - will fail)\n         - python \"/path/with spaces/script.py\" (correct)\n         - python /path/with spaces/script.py (incorrect - will fail)\n       - After ensuring proper quoting, execute the command.\n       - Capture the output of the command.\n\n    Usage notes:\n      - The command argument is required.\n      - You can specify an optional timeout in milliseconds (up to 600000ms / 10 minutes). If not specified, commands will timeout after 120000ms (2 minutes).\n      - It is very helpful if you write a clear, concise description of what this command does in 5-10 words.\n      - If the output exceeds 30000 characters, output will be truncated before being returned to you.\n      - VERY IMPORTANT: You MUST avoid using search commands like `find` and `grep`. Instead use Grep, Glob, or Task to search. You MUST avoid read tools like `cat`, `head`, `tail`, and `ls`, and use Read and LS to read files.\n      - If you _still_ need to run `grep`, STOP. ALWAYS USE ripgrep at `rg` first, which all Claude Code users have pre-installed.\n      - When issuing multiple commands, use the ';' or '&&' operator to separate them. DO NOT use newlines (newlines are ok in quoted strings).\n      - Try to maintain your current working directory throughout the session by using absolute paths and avoiding usage of `cd`. You may use `cd` if the User explicitly requests it.\n  \"#)\n  command string @description(\"The command to execute\")\n  timeout int? @description(\"Optional timeout in milliseconds (max 600000)\")\n  description string? @description(\"Clear, concise description of what this command does in 5-10 words\")\n}\n\nclass GlobTool {\n  action \"Glob\" @description(#\"\n    Fast file pattern matching tool that works with any codebase size\n    - Supports glob patterns like \"**/*.js\" or \"src/**/*.ts\"\n    - Returns matching file paths sorted by modification time\n    - Use this tool when you need to find files by name patterns\n    - When you are doing an open ended search that may require multiple rounds of globbing and grepping, use the Agent tool instead\n    - You have the capability to call multiple tools in a single response. It is always better to speculatively perform multiple searches as a batch that are potentially useful.\n  \"#)\n  pattern string @description(\"The glob pattern to match files against\")\n  path string? @description(\"The directory to search in. If not specified, the current working directory will be used. IMPORTANT: Omit this field to use the default directory. DO NOT enter 'undefined' or 'null' - simply omit it for the default behavior. Must be a valid directory path if provided.\")\n}\n\nclass GrepTool {\n  action \"Grep\" @description(#\"\n    Fast content search tool that works with any codebase size\n    - Searches file contents using regular expressions\n    - Supports full regex syntax (eg. \"log.*Error\", \"function\\s+\\w+\", etc.)\n    - Filter files by pattern with the include parameter (eg. \"*.js\", \"*.{ts,tsx}\")\n    - Returns file paths with at least one match sorted by modification time\n    - Use this tool when you need to find files containing specific patterns\n    - If you need to identify/count the number of matches within files, use the Bash tool with `rg` (ripgrep) directly. Do NOT use `grep`.\n    - When you are doing an open ended search that may require multiple rounds of globbing and grepping, use the Agent tool instead\n  \"#)\n  pattern string @description(\"The regular expression pattern to search for in file contents\")\n  path string? @description(\"The directory to search in. Defaults to the current working directory.\")\n  include string? @description(\"File pattern to include in the search (e.g. '*.js', '*.{ts,tsx}')\")\n}\n\nclass LSTool {\n  action \"LS\" @description(#\"\n    Lists files and directories in a given path. The path parameter must be an absolute path, not a relative path. You can optionally provide an array of glob patterns to ignore with the ignore parameter. You should generally prefer the Glob and Grep tools, if you know which directories to search.\n  \"#)\n  path string @description(\"The absolute path to the directory to list (must be absolute, not relative)\")\n  ignore string[]? @description(\"List of glob patterns to ignore\")\n}\n\nclass ExitPlanModeTool {\n  action \"exit_plan_mode\" @description(#\"\n    Use this tool when you are in plan mode and have finished presenting your plan and are ready to code. This will prompt the user to exit plan mode.\n  \"#)\n  plan string @description(\"The plan you came up with, that you want to run by the user for approval. Supports markdown. The plan should be pretty concise.\")\n}\n\nclass ReadTool {\n  action \"Read\" @description(#\"\n    Reads a file from the local filesystem. You can access any file directly by using this tool.\n    Assume this tool is able to read all files on the machine. If the User provides a path to a file assume that path is valid. It is okay to read a file that does not exist; an error will be returned.\n\n    Usage:\n    - The file_path parameter must be an absolute path, not a relative path\n    - By default, it reads up to 2000 lines starting from the beginning of the file\n    - You can optionally specify a line offset and limit (especially handy for long files), but it's recommended to read the whole file by not providing these parameters\n    - Any lines longer than 2000 characters will be truncated\n    - Results are returned using cat -n format, with line numbers starting at 1\n    - This tool allows Claude Code to read images (eg PNG, JPG, etc). When reading an image file the contents are presented visually as Claude Code is a multimodal LLM.\n    - You have the capability to call multiple tools in a single response. It is always better to speculatively read multiple files as a batch that are potentially useful. \n    - You will regularly be asked to read screenshots. If the user provides a path to a screenshot ALWAYS use this tool to view the file at the path. This tool will work with all temporary file paths like /var/folders/123/abc/T/TemporaryItems/NSIRD_screencaptureui_ZfB1tD/Screenshot.png\n    - If you read a file that exists but has empty contents you will receive a system reminder warning in place of file contents.\n  \"#)\n  file_path string @description(\"The absolute path to the file to read\")\n  offset int? @description(\"The line number to start reading from. Only provide if the file is too large to read at once\")\n  limit int? @description(\"The number of lines to read. Only provide if the file is too large to read at once.\")\n}\n\nclass EditTool {\n  action \"Edit\" @description(#\"\n    Performs exact string replacements in files. \n\n    Usage:\n    - You must use your `Read` tool at least once in the conversation before editing. This tool will error if you attempt an edit without reading the file. \n    - When editing text from Read tool output, ensure you preserve the exact indentation (tabs/spaces) as it appears AFTER the line number prefix. The line number prefix format is: spaces + line number + tab. Everything after that tab is the actual file content to match. Never include any part of the line number prefix in the old_string or new_string.\n    - ALWAYS prefer editing existing files in the codebase. NEVER write new files unless explicitly required.\n    - Only use emojis if the user explicitly requests it. Avoid adding emojis to files unless asked.\n    - The edit will FAIL if `old_string` is not unique in the file. Either provide a larger string with more surrounding context to make it unique or use `replace_all` to change every instance of `old_string`. \n    - Use `replace_all` for replacing and renaming strings across the file. This parameter is useful if you want to rename a variable for instance.\n  \"#)\n  file_path string @description(\"The absolute path to the file to modify\")\n  old_string string @description(\"The text to replace\")\n  new_string string @description(\"The text to replace it with (must be different from old_string)\")\n  replace_all bool? @description(\"Replace all occurences of old_string (default false)\")\n}\n\nclass EditOperation {\n  old_string string @description(\"The text to replace\")\n  new_string string @description(\"The text to replace it with\")\n  replace_all bool? @description(\"Replace all occurences of old_string. This parameter is optional and defaults to false.\")\n}\n\nclass MultiEditTool {\n  action \"MultiEdit\" @description(#\"\n    This is a tool for making multiple edits to a single file in one operation. It is built on top of the Edit tool and allows you to perform multiple find-and-replace operations efficiently. Prefer this tool over the Edit tool when you need to make multiple edits to the same file.\n\n    Before using this tool:\n\n    1. Use the Read tool to understand the file's contents and context\n    2. Verify the directory path is correct\n\n    To make multiple file edits, provide the following:\n    1. file_path: The absolute path to the file to modify (must be absolute, not relative)\n    2. edits: An array of edit operations to perform\n\n    IMPORTANT:\n    - All edits are applied in sequence, in the order they are provided\n    - Each edit operates on the result of the previous edit\n    - All edits must be valid for the operation to succeed - if any edit fails, none will be applied\n    - This tool is ideal when you need to make several changes to different parts of the same file\n    - For Jupyter notebooks (.ipynb files), use the NotebookEdit instead\n\n    CRITICAL REQUIREMENTS:\n    1. All edits follow the same requirements as the single Edit tool\n    2. The edits are atomic - either all succeed or none are applied\n    3. Plan your edits carefully to avoid conflicts between sequential operations\n\n    WARNING:\n    - The tool will fail if edits.old_string doesn't match the file contents exactly (including whitespace)\n    - The tool will fail if edits.old_string and edits.new_string are the same\n    - Since edits are applied in sequence, ensure that earlier edits don't affect the text that later edits are trying to find\n\n    When making edits:\n    - Ensure all edits result in idiomatic, correct code\n    - Do not leave the code in a broken state\n    - Always use absolute file paths (starting with /)\n    - Only use emojis if the user explicitly requests it. Avoid adding emojis to files unless asked.\n    - Use replace_all for replacing and renaming strings across the file. This parameter is useful if you want to rename a variable for instance.\n\n    If you want to create a new file, use:\n    - A new file path, including dir name if needed\n    - First edit: empty old_string and the new file's contents as new_string\n    - Subsequent edits: normal edit operations on the created content\n  \"#)\n  file_path string @description(\"The absolute path to the file to modify\")\n  edits EditOperation[] @description(\"Array of edit operations to perform sequentially on the file\")\n}\n\nclass WriteTool {\n  action \"Write\" @description(#\"\n    Writes a file to the local filesystem.\n\n    Usage:\n    - This tool will overwrite the existing file if there is one at the provided path.\n    - If this is an existing file, you MUST use the Read tool first to read the file's contents. This tool will fail if you did not read the file first.\n    - ALWAYS prefer editing existing files in the codebase. NEVER write new files unless explicitly required.\n    - NEVER proactively create documentation files (*.md) or README files. Only create documentation files if explicitly requested by the User.\n    - Only use emojis if the user explicitly requests it. Avoid writing emojis to files unless asked.\n  \"#)\n  file_path string @description(\"The absolute path to the file to write (must be absolute, not relative)\")\n  content string @description(\"The content to write to the file\")\n}\n\nclass NotebookReadTool {\n  action \"NotebookRead\" @description(#\"\n    Reads a Jupyter notebook (.ipynb file) and returns all of the cells with their outputs. Jupyter notebooks are interactive documents that combine code, text, and visualizations, commonly used for data analysis and scientific computing. The notebook_path parameter must be an absolute path, not a relative path.\n  \"#)\n  notebook_path string @description(\"The absolute path to the Jupyter notebook file to read (must be absolute, not relative)\")\n}\n\nclass NotebookEditTool {\n  action \"NotebookEdit\" @description(#\"\n    Completely replaces the contents of a specific cell in a Jupyter notebook (.ipynb file) with new source. Jupyter notebooks are interactive documents that combine code, text, and visualizations, commonly used for data analysis and scientific computing. The notebook_path parameter must be an absolute path, not a relative path. The cell_number is 0-indexed. Use edit_mode=insert to add a new cell at the index specified by cell_number. Use edit_mode=delete to delete the cell at the index specified by cell_number.\n  \"#)\n  notebook_path string @description(\"The absolute path to the Jupyter notebook file to edit (must be absolute, not relative)\")\n  cell_number int @description(\"The index of the cell to edit (0-based)\")\n  new_source string @description(\"The new source for the cell\")\n  cell_type string? @description(\"The type of the cell (code or markdown). If not specified, it defaults to the current cell type. If using edit_mode=insert, this is required.\")\n  edit_mode string? @description(\"The type of edit to make (replace, insert, delete). Defaults to replace.\")\n}\n\nclass WebFetchTool {\n  action \"WebFetch\" @description(#\"\n    - Fetches content from a specified URL and processes it using an AI model\n    - Takes a URL and a prompt as input\n    - Fetches the URL content, converts HTML to markdown\n    - Processes the content with the prompt using a small, fast model\n    - Returns the model's response about the content\n    - Use this tool when you need to retrieve and analyze web content\n\n    Usage notes:\n      - IMPORTANT: If an MCP-provided web fetch tool is available, prefer using that tool instead of this one, as it may have fewer restrictions. All MCP-provided tools start with \"mcp__\".\n      - The URL must be a fully-formed valid URL\n      - HTTP URLs will be automatically upgraded to HTTPS\n      - The prompt should describe what information you want to extract from the page\n      - This tool is read-only and does not modify any files\n      - Results may be summarized if the content is very large\n      - Includes a self-cleaning 15-minute cache for faster responses when repeatedly accessing the same URL\n  \"#)\n  url string @description(\"The URL to fetch content from\")\n  prompt string @description(\"The prompt to run on the fetched content\")\n  save_to_file string? @description(\"Path to save the fetched content to a file. Defaults to null, which means no file will be saved.\")\n}\n\nclass TodoItem {\n  content string\n  status \"pending\" | \"in_progress\" | \"completed\"\n  priority \"high\" | \"medium\" | \"low\"\n  id string\n}\n\nclass TodoReadTool {\n  action \"TodoRead\" @description(#\"\n    Use this tool to read the current to-do list for the session. This tool should be used proactively and frequently to ensure that you are aware of\n    the status of the current task list. You should make use of this tool as often as possible, especially in the following situations:\n    - At the beginning of conversations to see what's pending\n    - Before starting new tasks to prioritize work\n    - When the user asks about previous tasks or plans\n    - Whenever you're uncertain about what to do next\n    - After completing tasks to update your understanding of remaining work\n    - After every few messages to ensure you're on track\n\n    Usage:\n    - This tool takes in no parameters. So leave the input blank or empty. DO NOT include a dummy object, placeholder string or a key like \"input\" or \"empty\". LEAVE IT BLANK.\n    - Returns a list of todo items with their status, priority, and content\n    - Use this information to track progress and plan next steps\n    - If no todos exist yet, an empty list will be returned\n  \"#)\n}\n\nclass TodoWriteTool {\n  action \"TodoWrite\" @description(#\"\n    Use this tool to create and manage a structured task list for your current coding session. This helps you track progress, organize complex tasks, and demonstrate thoroughness to the user.\n    It also helps the user understand the progress of the task and overall progress of their requests.\n\n    When to Use This Tool\n    Use this tool proactively in these scenarios:\n\n    1. Complex multi-step tasks - When a task requires 3 or more distinct steps or actions\n    2. Non-trivial and complex tasks - Tasks that require careful planning or multiple operations\n    3. User explicitly requests todo list - When the user directly asks you to use the todo list\n    4. User provides multiple tasks - When users provide a list of things to be done (numbered or comma-separated)\n    5. After receiving new instructions - Immediately capture user requirements as todos\n    6. When you start working on a task - Mark it as in_progress BEFORE beginning work. Ideally you should only have one todo as in_progress at a time\n    7. After completing a task - Mark it as completed and add any new follow-up tasks discovered during implementation\n\n    When NOT to Use This Tool\n\n    Skip using this tool when:\n    1. There is only a single, straightforward task\n    2. The task is trivial and tracking it provides no organizational benefit\n    3. The task can be completed in less than 3 trivial steps\n    4. The task is purely conversational or informational\n\n    NOTE that you should not use this tool if there is only one trivial task to do. In this case you are better off just doing the task directly.\n\n    Task States and Management\n\n    1. Task States: Use these states to track progress:\n       - pending: Task not yet started\n       - in_progress: Currently working on (limit to ONE task at a time)\n       - completed: Task finished successfully\n\n    2. Task Management:\n       - Update task status in real-time as you work\n       - Mark tasks complete IMMEDIATELY after finishing (don't batch completions)\n       - Only have ONE task in_progress at any time\n       - Complete current tasks before starting new ones\n       - Remove tasks that are no longer relevant from the list entirely\n\n    3. Task Completion Requirements:\n       - ONLY mark a task as completed when you have FULLY accomplished it\n       - If you encounter errors, blockers, or cannot finish, keep the task as in_progress\n       - When blocked, create a new task describing what needs to be resolved\n       - Never mark a task as completed if:\n         - Tests are failing\n         - Implementation is partial\n         - You encountered unresolved errors\n         - You couldn't find necessary files or dependencies\n\n    4. Task Breakdown:\n       - Create specific, actionable items\n       - Break complex tasks into smaller, manageable steps\n       - Use clear, descriptive task names\n\n    When in doubt, use this tool. Being proactive with task management demonstrates attentiveness and ensures you complete all requirements successfully.\n  \"#)\n  todos TodoItem[] @description(\"The updated todo list\")\n}\n\nclass WebSearchTool {\n  action \"WebSearch\" @description(#\"\n    - Allows Claude to search the web and use the results to inform responses\n    - Provides up-to-date information for current events and recent data\n    - Returns search result information formatted as search result blocks\n    - Use this tool for accessing information beyond Claude's knowledge cutoff\n    - Searches are performed automatically within a single API call\n\n    Usage notes:\n      - Domain filtering is supported to include or block specific websites\n      - Web search is only available in the US\n  \"#)\n  query string @description(\"The search query to use\")\n  allowed_domains string[]? @description(\"Only include search results from these domains\")\n  blocked_domains string[]? @description(\"Never include search results from these domains\")\n}\n\nclass PytestRunTool {\n  action \"PytestRun\" @description(#\"\n    Run pytest tests and return results with detailed output formatting.\n\n    Usage:\n    - Executes pytest with specified options and paths\n    - Returns formatted test results including passed/failed counts\n    - Supports various pytest options like verbose mode, specific test selection\n    - Handles test discovery and execution with proper working directory context\n    - Provides truncated output with recovery instructions for large test suites\n    - Includes coverage information when available\n\n    Parameters:\n    - test_path: Optional path to specific test file or directory (defaults to discovering all tests)\n    - verbose: Enable verbose output (-v flag)\n    - capture: Control output capturing (default 'no' shows print statements)\n    - markers: Run only tests matching given mark expression\n    - keywords: Run only tests matching given keyword expression\n    - max_failures: Stop after N failures (--maxfail option)\n    - timeout: Override default timeout for long-running test suites\n\n    Examples:\n    - Run all tests: PytestRun with no parameters\n    - Run specific test: PytestRun with test_path=\"tests/test_agent.py\"\n    - Run with verbose output: PytestRun with verbose=true\n    - Run tests matching keyword: PytestRun with keywords=\"test_function_name\"\n  \"#)\n  test_path string? @description(\"Path to test file or directory to run (defaults to test discovery)\")\n  verbose bool? @description(\"Enable verbose output (-v flag)\")\n  capture string? @description(\"Output capture mode: 'sys' (default), 'no', 'fd'\")\n  markers string? @description(\"Run tests matching given mark expression (-m option)\")\n  keywords string? @description(\"Run tests matching keyword expression (-k option)\")\n  max_failures int? @description(\"Stop after N test failures (--maxfail option)\")\n  timeout int? @description(\"Override timeout in milliseconds (default 120000)\")\n}\n\nclass LintTool {\n  action \"Lint\" @description(#\"\n    Run Ruff linter for code quality checking with optional auto-fixing.\n\n    Usage:\n    - Performs fast Python linting using Ruff\n    - Supports auto-fixing of common issues\n    - Can target specific files or entire project\n    - Returns formatted lint results with line numbers and issue descriptions\n    - Handles large codebases with truncated output\n    - Provides helpful suggestions for fixing issues\n\n    Parameters:\n    - target_path: Path to file or directory to lint (defaults to current directory)\n    - fix: Automatically fix fixable lint issues\n    - show_fixes: Show what fixes would be applied without making changes\n    - select_codes: Comma-separated list of error codes to check (e.g. 'E,W,F')\n    - ignore: Comma-separated list of error codes to ignore\n    - format: Output format ('text', 'json', 'github', 'gitlab', 'junit', 'sarif')\n\n    Examples:\n    - Lint current directory: Lint with no parameters\n    - Lint specific file: Lint with target_path=\"main.py\"\n    - Auto-fix issues: Lint with fix=true\n    - Show potential fixes: Lint with show_fixes=true\n  \"#)\n  target_path string? @description(\"Path to lint (file or directory, defaults to '.')\")\n  fix bool? @description(\"Automatically fix fixable issues\")\n  show_fixes bool? @description(\"Show fixes without applying them\")\n  select_codes string? @description(\"Comma-separated error codes to check (e.g. 'E,W,F')\")\n  ignore string? @description(\"Comma-separated error codes to ignore\")\n  format string? @description(\"Output format: 'text' (default), 'json', 'github', 'gitlab'\")\n}\n\nclass TypeCheckTool {\n  action \"TypeCheck\" @description(#\"\n    Run static type checking using mypy or pyright for Python code analysis.\n\n    Usage:\n    - Performs static type analysis to catch type-related errors\n    - Supports both mypy and pyright type checkers\n    - Can target specific files or entire project\n    - Returns formatted type check results with error locations\n    - Handles incremental checking for faster results\n    - Provides clear error messages with file and line numbers\n\n    Parameters:\n    - target_path: Path to type check (file or directory, defaults to '.')\n    - checker: Type checker to use ('mypy' or 'pyright', defaults to 'mypy')\n    - strict: Enable strict type checking mode\n    - ignore_missing_imports: Ignore errors from missing type stubs\n    - incremental: Use incremental mode for faster checking (mypy only)\n    - config_file: Path to configuration file (mypy.ini, pyproject.toml, etc.)\n\n    Examples:\n    - Type check current directory: TypeCheck with no parameters\n    - Type check specific file: TypeCheck with target_path=\"main.py\"\n    - Strict type checking: TypeCheck with strict=true\n    - Use pyright instead: TypeCheck with checker=\"pyright\"\n  \"#)\n  target_path string? @description(\"Path to type check (defaults to '.')\")\n  checker string? @description(\"Type checker: 'mypy' (default) or 'pyright'\")\n  strict bool? @description(\"Enable strict type checking\")\n  ignore_missing_imports bool? @description(\"Ignore missing import errors\")\n  incremental bool? @description(\"Use incremental mode (mypy only)\")\n  config_file string? @description(\"Path to configuration file\")\n}\n\nclass FormatTool {\n  action \"Format\" @description(#\"\n    Format Python code using Black formatter with consistent style.\n\n    Usage:\n    - Formats Python code according to Black's style guide\n    - Can format specific files or entire directories\n    - Supports diff preview before applying changes\n    - Returns summary of formatting changes made\n    - Handles large codebases efficiently\n    - Ensures consistent code style across the project\n\n    Parameters:\n    - target_path: Path to format (file or directory, defaults to '.')\n    - check_only: Only check if files would be reformatted without changing them\n    - diff: Show diff of changes that would be made\n    - line_length: Override maximum line length (default 88)\n    - skip_string_normalization: Don't normalize string quotes\n    - target_version: Python target version (e.g. 'py38', 'py39', 'py310')\n\n    Examples:\n    - Format current directory: Format with no parameters\n    - Check formatting only: Format with check_only=true\n    - Show formatting diff: Format with diff=true\n    - Custom line length: Format with line_length=100\n  \"#)\n  target_path string? @description(\"Path to format (defaults to '.')\")\n  check_only bool? @description(\"Check formatting without making changes\")\n  diff bool? @description(\"Show diff of formatting changes\")\n  line_length int? @description(\"Maximum line length (default 88)\")\n  skip_string_normalization bool? @description(\"Don't normalize string quotes\")\n  target_version string? @description(\"Python target version (py38, py39, py310, etc.)\")\n}\n\nclass DependencyTool {\n  action \"Dependency\" @description(#\"\n    Check and manage Python dependencies and package versions.\n\n    Usage:\n    - Compares installed packages with requirements\n    - Identifies outdated or missing dependencies\n    - Can check if specific packages can be imported\n    - Can show dependency tree and conflicts\n    - Supports multiple requirements file formats\n    - Returns formatted dependency analysis\n    - Helps maintain project dependency health\n\n    Parameters:\n    - check_type: Type of check ('outdated', 'missing', 'tree', 'imports')\n    - requirements_file: Path to requirements file (defaults to 'pyproject.toml')\n    - packages: List of package names to check (for 'imports' check_type)\n    - update_available: Show available updates for packages\n    - include_dev: Include development dependencies in analysis\n\n    Examples:\n    - Check missing deps: Dependency with check_type=\"missing\"\n    - Find outdated packages: Dependency with check_type=\"outdated\"\n    - Show dependency tree: Dependency with check_type=\"tree\"\n    - Check imports: Dependency with check_type=\"imports\", packages=[\"pandas\", \"numpy\"]\n    - Include dev deps: Dependency with include_dev=true\n  \"#)\n  check_type string? @description(\"Check type: 'outdated', 'missing', 'tree', 'imports'\")\n  requirements_file string? @description(\"Requirements file path (default 'pyproject.toml')\")\n  packages string[]? @description(\"Package names to check (for 'imports' check_type)\")\n  update_available bool? @description(\"Show available package updates\")\n  include_dev bool? @description(\"Include development dependencies\")\n}\n\nclass GitDiffTool {\n  action \"GitDiff\" @description(#\"\n    Compare files or directories against git HEAD or other references.\n\n    Usage:\n    - Shows differences between working directory and git references\n    - Can compare specific files or entire directories\n    - Supports various diff formats and context options\n    - Handles large diffs with intelligent truncation\n    - Useful for code review and change analysis\n    - Provides clear context about what has changed\n\n    Parameters:\n    - target_path: Path to diff (file or directory, defaults to all changes)\n    - reference: Git reference to compare against (default 'HEAD')\n    - staged: Show staged changes instead of working directory\n    - stat: Show diffstat summary instead of full diff\n    - context_lines: Number of context lines around changes\n    - ignore_whitespace: Ignore whitespace changes\n\n    Examples:\n    - Show all changes: GitDiff with no parameters\n    - Diff specific file: GitDiff with target_path=\"main.py\"\n    - Compare to different branch: GitDiff with reference=\"main\"\n    - Show staged changes: GitDiff with staged=true\n  \"#)\n  target_path string? @description(\"Path to diff (defaults to all changes)\")\n  reference string? @description(\"Git reference to compare (default 'HEAD')\")\n  staged bool? @description(\"Show staged changes\")\n  stat bool? @description(\"Show diffstat summary\")\n  context_lines int? @description(\"Context lines around changes (default 3)\")\n  ignore_whitespace bool? @description(\"Ignore whitespace changes\")\n}\n\nclass InstallPackagesTool {\n  action \"InstallPackages\" @description(#\"\n    Install Python packages using uv or pip with user permission.\n\n    Usage:\n    - Automatically detects whether to use uv or pip\n    - Installs packages with proper dependency resolution\n    - Provides clear feedback on installation success/failure\n    - Can install multiple packages at once\n    - Handles both production and development dependencies\n\n    IMPORTANT: This tool should only be used after the agent has:\n    1. Detected missing packages needed for a task\n    2. Asked the user for permission to install packages\n    3. Received explicit user approval\n\n    Parameters:\n    - packages: List of package names to install (required)\n    - dev: Install as development dependencies (optional, defaults to false)\n    - upgrade: Upgrade packages if already installed (optional, defaults to false)\n    - user_confirmed: Confirmation that user approved installation (required)\n\n    Examples:\n    - Install plotting libs: InstallPackages with packages=[\"pandas\", \"matplotlib\", \"seaborn\"], user_confirmed=true\n    - Install dev deps: InstallPackages with packages=[\"pytest\", \"black\"], dev=true, user_confirmed=true\n    - Upgrade packages: InstallPackages with packages=[\"numpy\"], upgrade=true, user_confirmed=true\n  \"#)\n  packages string[] @description(\"Package names to install (required)\")\n  dev bool? @description(\"Install as development dependencies (default false)\")\n  upgrade bool? @description(\"Upgrade packages if already installed (default false)\")\n  user_confirmed bool @description(\"User has confirmed installation (required for safety)\")\n}\n\nclass ArtifactManagementTool {\n  action \"ArtifactManagement\" @description(#\"\n    Manage and organize project artifacts in standard folders to avoid duplication.\n\n    Standard Folder Structure:\n    - scripts/ : Python scripts, code generators, analysis tools\n    - data/ : CSV files, datasets, JSON files, text data\n    - visualization/ : Plots, charts, images, visual outputs\n    - plots/ : Legacy plot folder (use visualization/ for new plots)\n\n    Usage:\n    - Check what artifacts already exist before creating new ones\n    - Find related outputs from previous work\n    - Organize new artifacts in appropriate folders\n    - Prevent token waste by reusing existing scripts/data\n    - Maintain clean project structure\n\n    IMPORTANT: Always check existing artifacts before creating new ones!\n    This saves tokens and builds on previous work instead of duplicating effort.\n\n    Parameters:\n    - action_type: What to do ('list', 'find', 'organize', 'clean')\n    - folder: Specific folder to work with (optional)\n    - pattern: File pattern to search for (optional)\n    - artifact_type: Type of artifact ('script', 'data', 'visualization', 'any')\n\n    Examples:\n    - List all scripts: ArtifactManagement with action_type=\"list\", artifact_type=\"script\"\n    - Find plotting scripts: ArtifactManagement with action_type=\"find\", pattern=\"*plot*\"\n    - Check data files: ArtifactManagement with action_type=\"list\", folder=\"data\"\n    - Organize outputs: ArtifactManagement with action_type=\"organize\"\n  \"#)\n  action_type string @description(\"Action to perform: 'list', 'find', 'organize', 'clean'\")\n  folder string? @description(\"Specific folder to work with (scripts/data/visualization/plots)\")\n  pattern string? @description(\"File pattern to search for (e.g., '*plot*', '*.csv')\")\n  artifact_type string? @description(\"Type of artifact: 'script', 'data', 'visualization', 'any'\")\n}\n\n// Union type for all tools\ntype ScaryTools =  EditTool | MultiEditTool | WriteTool | NotebookEditTool | TodoWriteTool\ntype CodingTools = PytestRunTool | LintTool | TypeCheckTool | FormatTool | DependencyTool | GitDiffTool | InstallPackagesTool | ArtifactManagementTool\ntype AgentTools = SubAgentTools | AgentTool\ntype SubAgentTools = BashTool | GlobTool | GrepTool | LSTool | ExitPlanModeTool | ReadTool | WebFetchTool | TodoReadTool | TodoWriteTool | WebSearchTool | ScaryTools | CodingTools\n",
    "agent.baml": "class Message {\n  role \"user\" | \"assistant\"\n  message string | AgentTools\n}\n\nclass ReplyToUser {\n  action \"reply_to_user\"\n  message string\n}\n\n// type ReplyString = string @assert({{ this[0] != \"[\" and this[0] != \"{\" }})\n\nfunction AgentLoop(state: Message[], working_dir: string) -> AgentTools | ReplyToUser {\n  client \"openai-responses/gpt-5-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are BAMMY, an advanced AI agent capable of handling complex software engineering and general tasks.\n\n    # Environment Context\n    Current working directory: {{ working_dir }}\n\n    # Core Capabilities\n    You have access to powerful tools for:\n    - File system operations (read, write, edit, search)\n    - Code analysis and manipulation\n    - Web research and data fetching\n    - Task planning and management\n    - Bash command execution\n    - Recursive sub-agent delegation\n\n    # Task Management Philosophy\n    IMPORTANT: Use TodoWrite and TodoRead tools extensively to:\n    - Break down complex tasks into manageable steps\n    - Track progress and maintain visibility\n    - Plan before executing\n    - Mark tasks as completed immediately when done\n    - Never batch multiple tasks before marking them complete\n\n    # Code and File Operations\n    - Always understand existing code conventions before making changes\n    - Follow existing patterns, naming conventions, and architectural decisions\n    - Check for existing libraries/frameworks before introducing new ones\n    - Never assume libraries are available - verify first\n    - Follow security best practices - never expose secrets or keys\n    - DO NOT add comments unless explicitly requested\n\n    # Dependency Management (IMPORTANT)\n    When you need Python packages for a task (plotting, data analysis, etc.):\n    1. FIRST check if packages are available: use Dependency with check_type=\"imports\", packages=[\"package1\", \"package2\"]\n    2. If packages are missing, ASK USER for permission: \"I need to install pandas, numpy for this task. Should I install them? [Y/N]\"\n    3. If user approves, use InstallPackages with user_confirmed=true\n    4. Then continue with the original task\n\n    Example workflow:\n    - User asks for plots → Check imports → Ask permission → Install packages → Generate plots\n    - Never give up or ask user to install manually - be proactive!\n\n    # Artifact Management (CRITICAL FOR EFFICIENCY)\n    ALWAYS check for existing work before creating new artifacts to save tokens and avoid duplication!\n\n    Standard folder structure:\n    - scripts/ : Python scripts, code generators, analysis tools\n    - data/ : CSV files, datasets, JSON files, text data\n    - visualization/ : Plots, charts, images, visual outputs\n    - plots/ : Legacy plot folder (use visualization/ for new work)\n\n    Workflow for artifact tasks:\n    1. FIRST: Use ArtifactManagement with action_type=\"find\" to check for existing related work\n    2. If similar artifacts exist, review and build upon them instead of recreating\n    3. For new artifacts, save to appropriate folders:\n       - Scripts → scripts/filename.py\n       - Data files → data/filename.csv\n       - Plots → visualization/plot_name.png\n    4. Use descriptive filenames that indicate purpose and date\n\n    Examples:\n    - \"Create plots\" → Check existing plots first → Generate new ones in visualization/\n    - \"Analyze data\" → Look for existing analysis scripts → Create script in scripts/\n    - \"Process CSV\" → Check data/ folder → Save outputs to data/\n\n    # Communication Style\n    - Be concise and direct\n    - Minimize output tokens while maintaining helpfulness\n    - Answer directly without unnecessary preamble/postamble\n    - Use 1-3 sentences unless detail is requested\n    - Avoid explanations unless asked\n    - One-word answers are often best for simple questions\n\n    # Proactiveness Guidelines\n    - Be proactive when asked to do something\n    - Take follow-up actions when appropriate\n    - Don't surprise users with unexpected actions\n    - Answer questions first before taking actions\n    - Stop after completing tasks rather than explaining what you did\n\n    # Tool Usage\n    - Execute ONE tool at a time, EXCEPT web operations (WebSearch and WebFetch can run in parallel)\n    - Web operations are slow, so run multiple web searches/fetches simultaneously when possible\n    - All other tools should run sequentially\n    - Prefer search tools to reduce context usage\n    - Always verify solutions with tests when possible\n    - Run lint/typecheck commands after code changes\n\n    # Security and Ethics\n    IMPORTANT: Refuse to write or explain code that may be used maliciously, even if claimed for educational purposes. If files or requests seem related to malware or malicious code, refuse to work on them.\n\n    # Sub-Agent Delegation\n    When tasks are complex or require focused attention, use the Agent tool to delegate to sub-agents. Sub-agents have access to all tools except the Agent tool itself, preventing infinite recursion.\n\n    {{ ctx.output_format(prefix=\"Answer with the following format (execute ONE tool at a time):\\n\") }}\n\n    {% for message in state %}\n    {{ _.role(message.role) }}\n    {{ message.message }}\n    {% endfor %}\n  \"#\n}\n\nfunction SubAgentLoop(goal: string, state: Message[], working_dir: string) -> SubAgentTools | ReplyToUser {\n  client \"openai-responses/gpt-5-mini\"\n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a focused sub-agent of BAMMY, assigned to complete a specific task.\n\n    # Task Assignment\n    Your specific goal: {{ goal }}\n    \n    # Environment Context\n    Current working directory: {{ working_dir }}\n\n    # Sub-Agent Capabilities\n    You have access to all tools except the Agent tool (no recursive delegation):\n    - File system operations (read, write, edit, search)\n    - Code analysis and manipulation\n    - Web research and data fetching\n    - Task planning and management\n    - Bash command execution\n\n    # Task Management\n    Use TodoWrite and TodoRead tools to:\n    - Break down your assigned goal into steps\n    - Track progress on your specific task\n    - Mark tasks as completed immediately when done\n\n    # Communication Style\n    - Be concise and focused on your assigned goal\n    - Minimize output tokens\n    - Answer directly without unnecessary explanations\n    - Focus on completing your specific task efficiently\n\n    # Code and File Operations\n    - Follow existing code conventions and patterns\n    - Check for existing libraries before introducing new ones\n    - Follow security best practices\n    - DO NOT add comments unless explicitly requested\n\n    # Dependency Management\n    When you need Python packages:\n    1. Check imports with Dependency tool (check_type=\"imports\")\n    2. Ask user permission if packages missing\n    3. Use InstallPackages with user_confirmed=true if approved\n    4. Continue with task - never give up on missing dependencies!\n\n    # Artifact Management\n    Check for existing work first to save tokens and avoid duplication:\n    1. Use ArtifactManagement to find existing related artifacts\n    2. Save new work to appropriate folders:\n       - scripts/ : Python scripts and analysis tools\n       - data/ : CSV files and datasets\n       - visualization/ : Plots and visual outputs\n    3. Use descriptive filenames with purpose and date\n\n    # Security\n    IMPORTANT: Refuse to work on code that may be used maliciously.\n\n    {{ ctx.output_format(prefix=\"Answer with the following format (execute ONE tool at a time):\\n\") }}\n\n    {{ _.role(\"user\") }}\n    You are working on the following goal:\n    {{ goal }}\n\n    {% for message in state %}\n    {{ _.role(message.role) }}\n    {{ message.message }}\n    {% endfor %}\n  \"#\n}\n\ntest TestName {\n  functions [AgentLoop]\n  args {\n    state [\n      {\n          role \"user\"\n          message #\"\n          what directory contains the file \"package.json\"?\n        \"#\n      }\n    ]\n    working_dir \"/Users/vbv/repos/ai-that-works/2025-10-21-agentic-rag-context-engineering\"\n  }\n}\n",
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Openai with chat completion\nclient<llm> CustomGPT5Chat {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Latest Anthropic Claude 4 models\nclient<llm> CustomOpus4 {\n  provider anthropic\n  options {\n    model \"claude-opus-4-1-20250805\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet4 {\n  provider anthropic\n  options {\n    model \"claude-sonnet-4-20250514\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-5-haiku-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// Example Google AI client (uncomment to use)\n// client<llm> CustomGemini {\n//   provider google-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     api_key env.GOOGLE_API_KEY\n//   }\n// }\n\n// Example AWS Bedrock client (uncomment to use)\n// client<llm> CustomBedrock {\n//   provider aws-bedrock\n//   options {\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\n//     region \"us-east-1\"\n//     // AWS credentials are auto-detected from env vars\n//   }\n// }\n\n// Example Azure OpenAI client (uncomment to use)\n// client<llm> CustomAzure {\n//   provider azure-openai\n//   options {\n//     model \"gpt-5\"\n//     api_key env.AZURE_OPENAI_API_KEY\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\n//     api_version \"2024-10-01-preview\"\n//   }\n// }\n\n// Example Vertex AI client (uncomment to use)\n// client<llm> CustomVertex {\n//   provider vertex-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     location \"us-central1\"\n//     // Uses Google Cloud Application Default Credentials\n//   }\n// }\n\n// Example Ollama client for local models (uncomment to use)\n// client<llm> CustomOllama {\n//   provider openai-generic\n//   options {\n//     base_url \"http://localhost:11434/v1\"\n//     model \"llama4\"\n//     default_role \"user\" // Most local models prefer the user role\n//     // No API key needed for local Ollama\n//   }\n// }\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT5Mini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT5Mini, CustomGPT5]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.214.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // You can also use custom LLM params with a custom client name from clients.baml like \"client CustomGPT5\" or \"client CustomSonnet4\"\n  client \"openai-responses/gpt-5-mini\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}

def get_baml_files():
    return _file_map